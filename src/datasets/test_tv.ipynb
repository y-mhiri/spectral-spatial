{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../datasets')\n",
    "\n",
    "sys.path.append('../algorithms')\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pansharpening import PANDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device (default is \"cpu\")\n",
    "device = \"cpu\" \n",
    "\n",
    "# Define dtype\n",
    "dtype = torch.float64\n",
    "\n",
    "# Define random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Define data path\n",
    "data_path = '/home/mhiriy/data/harvard.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_transform = transforms.Compose([transforms.ToTensor()]) # Transforms a the input data to torch tensors\n",
    "dataset = PANDataset(root_dir=data_path, split='train', transform= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 1392, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 17\n",
    "x = dataset[idx]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = dataset[idx]\n",
    "y = torch.tensor(x)\n",
    "y=y.unsqueeze(0).to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme après flou (bande 0): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 0): (130, 174)\n",
      "Forme après flou (bande 1): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 1): (130, 174)\n",
      "Forme après flou (bande 2): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 2): (130, 174)\n",
      "Forme après flou (bande 3): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 3): (130, 174)\n",
      "Forme après flou (bande 4): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 4): (130, 174)\n",
      "Forme après flou (bande 5): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 5): (130, 174)\n",
      "Forme après flou (bande 6): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 6): (130, 174)\n",
      "Forme après flou (bande 7): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 7): (130, 174)\n",
      "Forme après flou (bande 8): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 8): (130, 174)\n",
      "Forme après flou (bande 9): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 9): (130, 174)\n",
      "Forme après flou (bande 10): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 10): (130, 174)\n",
      "Forme après flou (bande 11): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 11): (130, 174)\n",
      "Forme après flou (bande 12): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 12): (130, 174)\n",
      "Forme après flou (bande 13): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 13): (130, 174)\n",
      "Forme après flou (bande 14): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 14): (130, 174)\n",
      "Forme après flou (bande 15): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 15): (130, 174)\n",
      "Forme après flou (bande 16): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 16): (130, 174)\n",
      "Forme après flou (bande 17): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 17): (130, 174)\n",
      "Forme après flou (bande 18): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 18): (130, 174)\n",
      "Forme après flou (bande 19): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 19): (130, 174)\n",
      "Forme après flou (bande 20): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 20): (130, 174)\n",
      "Forme après flou (bande 21): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 21): (130, 174)\n",
      "Forme après flou (bande 22): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 22): (130, 174)\n",
      "Forme après flou (bande 23): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 23): (130, 174)\n",
      "Forme après flou (bande 24): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 24): (130, 174)\n",
      "Forme après flou (bande 25): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 25): (130, 174)\n",
      "Forme après flou (bande 26): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 26): (130, 174)\n",
      "Forme après flou (bande 27): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 27): (130, 174)\n",
      "Forme après flou (bande 28): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 28): (130, 174)\n",
      "Forme après flou (bande 29): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 29): (130, 174)\n",
      "Forme après flou (bande 30): (1040, 1392)\n",
      "Forme après sous-échantillonnage (bande 30): (130, 174)\n"
     ]
    }
   ],
   "source": [
    "Y_H = x # Image multispectrale\n",
    "Y_H = torch.tensor(Y_H)\n",
    "Y_M = torch.sum(y, dim=3).unsqueeze(1)/y.shape[3]           # Matrice de transformation\n",
    "B = dataset.process_hyperspectral_image(x,8)\n",
    "B_t = dataset.process_hyperspectral_image_adjoint(B,8)                                                               # Transposée de B\n",
    "R = dataset.spectral()            # Matrice de projection\n",
    "B = torch.tensor(B)\n",
    "B_t = torch.tensor(B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d401193cbf1248e2a290d6e02a51e354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1040) must match the size of tensor b (130) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m pansharpening_model \u001b[38;5;241m=\u001b[39m ProximalGradient(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, lmbda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, lmbda_m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Exécution de l'optimisation\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m U_result \u001b[38;5;241m=\u001b[39m \u001b[43mpansharpening_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/spectral-spatial/src/datasets/../algorithms/tv.py:110\u001b[0m, in \u001b[0;36mProximalGradient.forward\u001b[0;34m(self, Y_H, Y_M, B, B_t, R, U_init)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Boucle d'optimisation\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter)):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# Gradient de f(U)\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     grad_U \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Mise à jour de U\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     U \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxg(U \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmbda \u001b[38;5;241m*\u001b[39m grad_U, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter)\n",
      "File \u001b[0;32m~/Documents/spectral-spatial/src/datasets/../algorithms/tv.py:25\u001b[0m, in \u001b[0;36mProximalGradient.grad_f\u001b[0;34m(self, U, Y_H, Y_M, B, B_t, R)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mCalcule le gradient de la fonction f(U).\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Terme 1 : Gradient de 1/2 ||Y_H - H U B||_F^2\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m grad1 \u001b[38;5;241m=\u001b[39m (\u001b[43mU\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m \u001b[38;5;241m-\u001b[39m Y_H) \u001b[38;5;241m@\u001b[39m B_t\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Terme 2 : Gradient de (lambda_m / 2) ||Y_M - R H U||_F^2\u001b[39;00m\n\u001b[1;32m     28\u001b[0m grad2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmbda_m \u001b[38;5;241m*\u001b[39m (R\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (R \u001b[38;5;241m@\u001b[39m U \u001b[38;5;241m-\u001b[39m Y_M))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1040) must match the size of tensor b (130) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Instanciation de l'algorithme\n",
    "from tv import ProximalGradient\n",
    "pansharpening_model = ProximalGradient(max_iter=100, lmbda=0.1, lmbda_m=1, tau=0.1, verbose=True)\n",
    "\n",
    "# Exécution de l'optimisation\n",
    "U_result = pansharpening_model.forward(Y_H, Y_M, B, B_t, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Image Multispectrale')\n",
    "plt.imshow(Y_H.numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Image Fusionnée')\n",
    "plt.imshow(U_result.detach().numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
